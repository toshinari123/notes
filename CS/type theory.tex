\documentclass{article}
\usepackage[utf8]{inputenc}
\usepackage{amsmath}
\usepackage{amssymb}
\usepackage[dvipsnames]{xcolor}
\usepackage[a4paper, total={6in, 10in}]{geometry}
\usepackage{tcolorbox}
\usepackage{mdframed}
\usepackage[hidelinks]{hyperref}
\usepackage{amsfonts}
\usepackage{mathrsfs}
\usepackage{centernot}
\usepackage{tabto}
\usepackage{graphicx}
\graphicspath{ {./images/} }
\usepackage[percent]{overpic}

\setlength{\jot}{10pt}
\NumTabs{8}

\newmdenv[
  topline=false,
  bottomline=false,
  skipabove=\topsep,
  skipbelow=\topsep,
  leftmargin=-10pt,
  rightmargin=-10pt,
  innertopmargin=0pt,
  innerbottommargin=0pt,
  linecolor=blue
]{siderules}
\newmdenv[
  topline=false,
  bottomline=false,
  skipabove=\topsep,
  skipbelow=\topsep,
  leftmargin=-10pt,
  rightmargin=-10pt,
  innertopmargin=0pt,
  innerbottommargin=0pt,
  linecolor=red
]{redrules}


\title{Types and Programming Languages\\Notes}
\author{toshinari tong}
\begin{document}
\maketitle
\section{Mathematical Preliminaries}
\subsection{Sets, Relations, and Functions}
A one-place relation on a set \(S\) is called a \textbf{predicate} on \(S\), written \(P(s)\) and regarding it as a function mapping elements of \(S\) to truth values.\\\\
A relation \(R\) on sets \(S, T\) is called a \textbf{partial function} if \((s,t_{1})\in R\) and \((s,t_{2})\in R\) implies \(t_{1}=t_{2}\).\\\\
If \(dom(R)=S\), then \(R\) is a \textbf{total function} (or just function).\\\\
A partial function is said to be \textbf{defined} on an argument \(s\in S\) if \(s\in dom(R)\) and undefined otherwise.
We write \(f(x)\uparrow\) to mean \(f\) is undefined on \(x\) and \(f(x)\downarrow\) to mean \(f\) is defined on \(x\).
We write \(f(x)=fail\) when \(f\) returns a failure result (it is defined). Formally, it is actually a function \(S\to T\cup\{fail\}\).\\\\
Suppose \(R\) is a binary relation on a set \(S\) and \(P\) is a predicate on \(S\). We say that \(P\) is \textbf{preserved} by \(R\) if \(s\;R\; s'\) and \(P(s)\) implies \(P(s')\).
\subsection{Ordered Sets}
\(R\) is \textbf{antisymmetric} if \(s\;R\; t\) and \(t\;R\; s\) implies \(s=t\).\\\\
A reflexive and transitive relation is a \textbf{preorder}, written with symbols like \(\le\) or \(\subseteq\). \(s<t\) means \(s\le t\land s\neq t\).\\\\
A preorder that is antisymmetric is called a \textbf{partial order}. A partial order is a \textbf{total order} if \(\forall s,t\in S\) either \(s\le t\) or \(t\le s\).\\\\
An element \(j\in S\) is a \textbf{join} or \textbf{least upper bound} of \(s\) and \(t\) if \(s\le j\) and \(t\le j\) and \((\forall k\in S,s\le k,t\le k)\;j\le k\).\\\\
An element \(m\in S\) is a \textbf{meet} or \textbf{greatest lower bound} of \(s\) and \(t\) if \(m\le s\) and \(m\le t\) and \((\forall n\in S,n\le s,n\le t)\;n\le m\).\\\\
The \textbf{reflexive closure} is the smallest reflexive relation \(R'\) that contains \(R\). (If some other reflexive relation \(R\subseteq R''\) then \(R'\subseteq R''\))\\\\
The \textbf{transitive closure} is the smallest transitive relation that contains \(R\), denoted \(R^{+}\). The \textbf{reflexive and transitive closure} of \(R\) is denoted \(R^{*}\).\\
\begin{siderules}\color{blue}\textit{EXERCISE 2.2.6}\color{black}\\\\
\color{blue}Suppose we are given a relation \(R\) on a set \(S\). Define \(R'=R\cup\{(s,s)\;|\;s\in S\}\). Show that \(R'\) is the reflexive closure of \(R\).\\\\\color{black}
Every reflexive relation that contains \(R\) must contain \(R\) and \(\{(s,s)\;|\;s\in S\}\).
\end{siderules}
\begin{siderules}\color{blue}\textit{EXERCISE 2.2.7}\color{black}\\\\
\color{blue} Define the following sequence of sets of pairs: \(R_{0}=R,R_{i+1}=R_{i}\cup\{(s,u)\;|\;\exists t\;(s,t)\in R_{i}\land (t,u)\in R_{i}\}\)
Show that \(R^{+}=\bigcup_{i}R_{i}\).\\\\\color{black}
If a transitive relation contains \(R_{i}\), then it must contain \(R_{i+1}\). By induction, \(R^{+}=\bigcup_{i}R_{i}\).
\end{siderules}
\begin{siderules}\color{blue}\textit{EXERCISE 2.2.8}\color{black}\\\\
\color{blue} Suppose \(R\) is a binary relation on a set \(S\) and \(P\) is a predicate preserved by \(R\). Show that \(P\) is also preserved by \(R^{*}\).\\\\\color{black}
\(s\;R^{*}\; s\) and \(P(s)\) implies \(P(s)\); \(t\;R^{*}\; v\), \(t\;R\; u\), \(u\;R\; v\) and \(P(t)\) implies \(P(v)\).
\end{siderules}
Suppose we have a preorder \(\le\) on a set \(S\). A \textbf{decreasing chain} is a sequence such that \(s_{i+1}<s_{i}\) for every \(i\).\\\\
We say that \(\le\) is \textbf{well founded} if it contains no infinite decreasing chains.
\subsection{Sequences}
A \textbf{sequence} is written by listing its elements, separated by commas. Commas are used as both the "cons" operation for adding an element to either end of a sequence and as the "append" operation on sequences.
The sequence of numbers from \(1\) to \(n\) is abbreviated \(1..n\). The empty sequence is written as \(\bullet\) or as a blank.
\subsection{induction}
AXIOM: principle of ordinary induction on natural numbers\\
Suppose \(P\) is a predicate on the natural numbers.\\
\null\qquad If \(P(0)\)\\
\null\qquad and, for all \(i\), \(P(i)\) \(\Longrightarrow\) \(P(i+1)\),\\
\null\qquad then \(P(n)\) holds for all \(n\).\\\\
AXIOM: principle of complete induction on natural numbers\\
Suppose \(P\) is a predicate on the natural numbers.\\
\null\qquad If, for each natural number \(n\)\\
\null\qquad given \(P(i)\) for all \(i < n\) we can show \(P(n)\)\\
\null\qquad then \(P(n)\) holds for all \(n\).\\\\
The \textbf{lexicographic order} on pairs of natural numbers is defined as follows: \((m,n)\le(m',n')\) iff \(m<m'\) or else \(m=m'\) and \(n\le n'\).\\\\
AXIOM: principle of complete induction on natural numbers\\
Suppose \(P\) is a predicate on pairs of natural numbers.\\
\null\qquad If, for each pair of natural numbers \((m,n)\)\\
\null\qquad given \(P(m',n')\) for all \((m'n')<(m,n)\) we can show \(P(m,n)\)\\
\null\qquad then \(P(m,n)\) holds for all \(m,n\).\\\\
The lexicographic induction principle is the basis for proofs by \textbf{nested infuction}, where some case of an inductive proof proceeds "by an inner induction".
\section{Untyped Arithmetic Expressions}
\subsection{Introduction}
\texttt{t ::=}\\
\null\qquad \texttt{true}\\
\null\qquad \texttt{false}\\
\null\qquad \texttt{if t then t else t}\\
\null\qquad \texttt{0}\\
\null\qquad \texttt{succ t}\\
\null\qquad \texttt{pred t}\\
\null\qquad \texttt{iszero t}\\\\
The first line declares we are defining the set of \textbf{terms}, and each following line gives one alternative syntactic form for terms.\\\\
\texttt{t} is called a \textbf{metavariable}. It is not a variable of the \textbf{object language} - the simple programming language whose syntax we are currently describing - 
but rather of the \textbf{metalanguage} - the notation in which the description is given.\\\\
Here are some examples of programs with results:\\\\
\texttt{iszero(pred(succ(0));}\\\\
\texttt{>>> true}\\\\
For brevity, \texttt{succ(succ(succ(0)))} is written as \texttt{3}. Results of evaluation are always boolean constants or numbers. Such terms are called \textbf{values}.
\subsection{Syntax}
The set of \textbf{terms} is the smallest set \(\mathcal{T}\) s.t.
\begin{enumerate}
\item\(\{\texttt{true},\texttt{false},\texttt{0}\}\subseteq\mathcal{T}\)
\item if \(\texttt{t}_{1}\in\mathcal{T}\), then \(\{\texttt{succ t}_{1},\texttt{pred t}_{1},\texttt{iszero t}_{1}\}\subseteq\mathcal{T}\)
\item if \(\texttt{t}_{1}\in\mathcal{T}\),\(\texttt{t}_{2}\in\mathcal{T}\), and \(\texttt{t}_{3}\in\mathcal{T}\), then \(\texttt{if t}_{1}\texttt{ then t}_{2}\texttt{ else t}_{3}\in\mathcal{T}\)
\end{enumerate}
We are defining \(\mathcal{T}\) as a set of \textbf{trees}, not as a set of strings.\\\\
Rules with no premises are often called \textbf{axioms}, and the term \textbf{inference rule} is used generically to include both axioms and rules with one or more premises.\\\\
What we are calling inference rules are actually \textbf{rule schemas}, since their premises and conclusions may include metavariables.
Each schema represents the infinite set of \textbf{concrete rules} that can be obtained.\\\\
\subsection{Induction on Terms}
\(Consts(\texttt{true})\)\tab\tab\tab\(=\;\{\texttt{true}\}\)\\
\(Consts(\texttt{false})\)\tab\tab\tab\(=\;\{\texttt{false}\}\)\\
\(Consts(\texttt{0})\)\tab\tab\tab\(=\;\{\texttt{0}\}\)\\
\(Consts(\texttt{succ t}_{1})\)\tab\tab\tab\(=\;Consts(\texttt{t}_{1})\)\\
\(Consts(\texttt{pred t}_{1})\)\tab\tab\tab\(=\;Consts(\texttt{t}_{1})\)\\
\(Consts(\texttt{iszero t}_{1})\)\tab\tab\tab\(=\;Consts(\texttt{t}_{1})\)\\
\(Consts(\texttt{if t}_{1}\texttt{ then t}_{2}\texttt{ else t}_{3})\)\tab\(=\;Consts(\texttt{t}_{1})\cup Consts(\texttt{t}_{2})\cup Consts(\texttt{t}_{3})\)\\\\
\(size(\texttt{true})\)\tab\tab\tab\(=\;1\)\\
\(size(\texttt{false})\)\tab\tab\tab\(=\;1\)\\
\(size(\texttt{0})\)\tab\tab\tab\tab\(=\;1\)\\
\(size(\texttt{succ t}_{1})\)\tab\tab\tab\(=\; size(\texttt{t}_{1})+1\)\\
\(size(\texttt{pred t}_{1})\)\tab\tab\tab\(=\; size(\texttt{t}_{1})+1\)\\
\(size(\texttt{iszero t}_{1})\)\tab\tab\tab\(=\; size(\texttt{t}_{1})+1\)\\
\(size(\texttt{if t}_{1}\texttt{ then t}_{2}\texttt{ else t}_{3})\)\tab\(=\; size(\texttt{t}_{1})+ size(\texttt{t}_{2})+ size(\texttt{t}_{3})+1\)\\\\
\(depth(\texttt{true})\)\tab\tab\tab\(=\;1\)\\
\(depth(\texttt{false})\)\tab\tab\tab\(=\;1\)\\
\(depth(\texttt{0})\)\tab\tab\tab\tab\(=\;1\)\\
\(depth(\texttt{succ t}_{1})\)\tab\tab\tab\(=\; depth(\texttt{t}_{1})+1\)\\
\(depth(\texttt{pred t}_{1})\)\tab\tab\tab\(=\; depth(\texttt{t}_{1})+1\)\\
\(depth(\texttt{iszero t}_{1})\)\tab\tab\tab\(=\; depth(\texttt{t}_{1})+1\)\\
\(depth(\texttt{if t}_{1}\texttt{ then t}_{2}\texttt{ else t}_{3})\)\tab\(=\; \max(depth(\texttt{t}_{1}),depth(\texttt{t}_{2}),depth(\texttt{t}_{3}))+1\)\\
\begin{redrules}
\color{red}Principles of induction on terms\color{black}\\\\
Suppose \(P\) is a predicate on terms.\\
If, for each term \texttt{s},\\
\null\qquad given \(P(\texttt{r})\) for all (choose 1 below)\\
\null\qquad \null\qquad [\texttt{r} such that \(depth(\texttt{r})<depth(\texttt{s})\)]\\
\null\qquad \null\qquad [\texttt{r} such that \(size(\texttt{r})<size(\texttt{s})\)]\\
\null\qquad \null\qquad [immediate subterms \texttt{r} of \texttt{s}]\\
\null\qquad we can show \(P(\texttt{s})\).\\
then \(P(\texttt{s})\) holds for all \texttt{s}.
\end{redrules}
The choice of induction principle is determined by which one leads to a simpler structure for the proof at hand-it is inter-derivable, and commonly structural induction is used wherever possible.
\subsection{Semantic Styles}
We need a precise definition of how terms are evaluated-the \textbf{semantics}:
\begin{enumerate}
\item \textbf{Operational semantics} specifies the behaviour of a programming language by defining a simple \textbf{abstract machine} for it.
    A \textbf{state} of the machine is just a term, and that machine's behaviour is defined by a \textbf{transition function} that for each state either gives the next state by performing a step of simplification (\textbf{small-step} style / \textbf{structural operational semantics}) on the term 
    or declares that the machine has halted. The \textbf{meaning} of a term \texttt{t} can be taken to be the final state that the machine reaches.
    It is sometimes useful to give 2 or more different operational semantics for a single language - some more abstract and others closer to the strictires manipulated by an actual interpreter or compiler.
\item \textbf{Denotational semantics} takes a more abstract view of taking the meaning of a term to be some mathematical object. Giving denotational semantics for a language consists of finding a collection of \textbf{semantic domains} 
    and then defining an \textbf{interpretation function} mapping terms into elements of these domains. The search for appropriate semantic domains for modeling various language features is known as \textbf{domain theory}. 
    Denotational semantics highlights the essential concepts of the language, can derive powerful laws for reasoning about program behaviours such as laws for proving two programs have exactly the same behaviour, and it is evident that some things are impossible in a language 
    by the properties of the semantic domains.
\item \textbf{Axiomatic semantics} is a more direct approach: it takes the laws themselves as the definition of the language. They focus acctention on the process of reasoning about programs, and has given computer science powerful ideas such as \textbf{invariants}.
\end{enumerate}
The bÃªte noire of denotational semantics turned out to be the treatment of nondeterminism
and concurrency; for axiomatic semantics, it was procedures.\\\\
Operational semantics is used exlusively in this book.
\subsection{Evaluation}
\includegraphics[width=15cm]{type1}\\
The left-hand column is a grammar defining 2 sets of expressions; the right-hand column defines an \textbf{evaluation relation} on terms, written \(\texttt{t}\to \texttt{t}'\) and pronounced "\texttt{t} evaluates to \texttt{t}' in one step".
The first 2 inference rules have no permises; for the third evaluation rule, it means that a machine in state \(\texttt{if t}_{1}\texttt{ then t}_{2}\texttt{ else t}_{3}\) can take a step to \(\texttt{if t}_{1}'\texttt{ then t}_{2}\texttt{ else t}_{3}\) 
if another machine whose state is \(\texttt{t}_{1}\) can take a step to state \(\texttt{t}_{1}'\).\\\\
What the rules don't say is just as important: The constants \texttt{true} and \texttt{false} doesn't evaluate to anything; the term \texttt{if true then (if false then false else false) else true} doesn't evaluate to \texttt{if true then false else true}, as our only choice 
is to evaluate the outer conditional first. This interplay between rules determines a particular \textbf{evaluation strategy}: to evaluate a conditional first evaluate its guard; thus the first 2 rules is sometimes referred to as \textbf{computation rules} and the last one as a \textbf{congruence rule}.\\\\
An \textbf{instance} of an inference rule is obtained by consistently replacing each metavariable by the same term. A rule is \textbf{satisfied} by a relation if for each instance of the rule either the conclusion is in the relation or one of the premises is not. 
The \textbf{one-step evaluation} relation \(\to\) is the smallest binary relation on terms satisfying the rules in the figure. When the pair \((\texttt{t},\texttt{t}')\) is in the evaluation relation, 
we say that "the evaluation \textbf{statement} or \textbf{judgement} \(\texttt{t}\to \texttt{t}'\) is \textbf{derivable}". The derivability of a given statement can be justified by exhibiting a \textbf{derivation tree} whose leaves are labeled with rules without premises and whos internal nodes are labeled with inference rules.\\
\begin{redrules}\color{red}Determinacy of one-step evaluation \color{black} If \(\texttt{t}\to \texttt{t}'\) and \(\texttt{t}\to \texttt{t}''\), then \(\texttt{t}'=\texttt{t}''\).\\\\
\textit{Proof.} By induction on a derivation of \(\texttt{t}\to \texttt{t}'\). If the last rule used in the derivation of \(\texttt{t}\to \texttt{t}'\) is E-IFTRUE, then we know \(\texttt{t}\) has the form \(\texttt{if t}_{1}\texttt{ then t}_{2}\texttt{ else t}_{3}\) where \(\texttt{t}_{1}=\texttt{true}\). It is obvious that the last rule in the derivation of \(\texttt{t}\to \texttt{t}''\) 
cannot be E-IFFALSE, since we cannot have both \(\texttt{t}_{1}=\texttt{true}\) and \(\texttt{t}_{1}=\texttt{false}\). The last rule in the second derivation cannot be E-IF either, since the premise of this rule demands that \(\texttt{t}_{1}\to \texttt{t}_{1}'\), but we have observed that \(\texttt{true}\) does not evaluate to anything. It follows that the last rule can only be E-IFTRUE, and that \(\texttt{t}'=\texttt{t}''\).
Similarly, if the last rule used in the first derivation is E-IFFALSE, then the last rule in the second derivation must be the same and the result is immediate.\\\\
If the last rule used in the derivation of \(\texttt{t}\to \texttt{t}'\)  is E-IF, then \texttt{t} has the form \(\texttt{if t}_{1}\texttt{ then t}_{2}\texttt{ else t}_{3}\) where \(\texttt{t}_{1}\to \texttt{t}_{1}'\) for some \(\texttt{t}_{1}'\).
By the same reasoning as above, the last rule in the derivation of \(\texttt{t}\to \texttt{t}''\) can only be E-IF, then \texttt{t} has the form \(\texttt{if t}_{1}\texttt{ then t}_{2}\texttt{ else t}_{3}\) where \(\texttt{t}_{1}\to \texttt{t}_{1}''\) for some \(\texttt{t}_{1}''\).
Now the induction hypothesis applies, yielding \(\texttt{t}_{1}'=\texttt{t}_{1}''\), which implies that \(\texttt{t}'=\texttt{t}''\).
\end{redrules}
A term \texttt{t} is in \textbf{normal form} if no evaluation rule applies to it.\\\\
\color{red}Theorem \color{black} every value is in normal form.\\
\begin{redrules}
\color{red}Theorem \color{black} In the current system, if \texttt{t} is in normal form, then \texttt{t} is a value.\\\\
\textit{Proof.} Suppose \(\texttt{t}\) is not a value. It is easy to show by structural induction on \texttt{t} that it is not a normal form.
\end{redrules}
The \textbf{multi-step evaluation} \(\to^{*}\) is the reflexive, transitive closure of one-step evaluation.\\
\begin{redrules}\color{red}
Uniqueness of normal forms \color{black} If \(\texttt{t}\to^{*}\texttt{u}\) and \(\texttt{t}\to^{*}\texttt{u}'\), where \(\texttt{u}\) and \(\texttt{u}'\) are both normal forms, then \(\texttt{u}=\texttt{u}'\).\\\\
\textit{Proof.} Corollary of the determinacy of single-step evaluation.
\end{redrules}
The last property of evaluation we consider is the fact that every term can be evaluated to a value. Most termination proofs in computer science has the same form: we choose some well-founded set \(S\) and a function \(f\) mapping machine states into \(S\).
Next, we show that whenever a machine state \texttt{t} can take a step to \texttt{t}', \(f(\texttt{t}')<f(\texttt{t})\). Since \(S\) is well-founded, there can be no infinite decreasing chain, and hance no infinite evaluation sequence. \(f\) is often called a \textbf{termination measure}.\\
\begin{redrules}\color{red}
Termination of evaluation \color{black} For every term \texttt{t} there is some normal form \(\texttt{t}'\) s.t. \(\texttt{t}\to^{*}\texttt{t}'\).\\\\
\textit{Proof.} Size of the term is a termination measure.
\end{redrules}
\includegraphics[width=15cm]{type3}\\
You cannot use E-PREDSUCC to evaluate \texttt{pred(succ(pred 0))} to \texttt{pred 0}.
\begin{siderules}\color{blue}\textit{EXERCISE 3.5.14}\color{black}\\\\
    \color{blue}Show that Determinacy of one-step evaluation is also valid for evaluation relation on arithmetic expressions.\\\\\color{black}
    Last is E-SUCC: unique form, second derivation must be E-SUCC as well, induction hypothesis;\\
    Last is E-PREDZERO: cannot be E-PRED because \texttt{0} doesn't evaluate to anything, second derivation must be E-PREDZERO;\\
    Last is E-PREDSUCC: cannot be E-PRED because \(\texttt{succ nv}_{1}\) doesn't evaluate, second derivation must be E-PREDSUCC;\\
    Last is E-PRED: unique form, second derivation must be E-PRED, induction hypothesis;\\
    Last is E-ISZEROZERO: cannot be E-ISZERO because ..., second derivation must be same;\\
    Last is E-ISZEROSUCC: cannot be E-ISZERO because ..., second derivation must be same;\\
    Last is E-ISZERO: unique form, second derivation must be same, induction hypothesis.
\end{siderules}
A closed term is \textbf{stuck} if it is in normal form but not a value (e.g. \texttt{succ false})\\\\
\begin{siderules}\color{blue}\textit{EXERCISE 3.5.16}\color{black}\\\\
    \includegraphics[width=10cm]{type4}\\
\color{blue}Show that these two treatments of run-time errors agree.\color{black}\\\\
Evaluates to \texttt{wrong} in the second treatment \(\Longleftrightarrow\) stuck in the first treatment.
\end{siderules}
\begin{siderules}\color{blue}\textit{EXERCISE 3.5.17}\color{black}\\\\
\color{blue} An alternative style of operational semantics is \textbf{big-step} semantics, formulating the notion of "this term evaluates to that final value", written \(\texttt{t}\Downarrow \texttt{v}\).\\
\includegraphics[width=10cm]{type5}\\
Show that \(\texttt{t}\to^{*} \texttt{v}\) iff \(\texttt{t}\Downarrow \texttt{v}\).\\\\\color{black}
Apply structural induction on B-rules to show \(\texttt{t}\Downarrow \texttt{v}\) implies \(\texttt{t}\to^{*}\texttt{v}\); 
\[\texttt{t}\to^{*}\texttt{t}\;\;\;\;\frac{\texttt{t}\to \texttt{t}'}{\texttt{t}\to^{*} \texttt{t}'}\;\;\;\;\frac{\texttt{t}\to^{*}\texttt{t}'\;\;\;\;\texttt{t}'\to^{*}\texttt{t}''}{\texttt{t}\to^{*}\texttt{t}''}\]
\color{red}idk how to do the other way\color{black}
\end{siderules}
\pagebreak
\section{An ML Implementation of Arithmetic Expressions}
\texttt{type term =\\
    TmTrue of info\\
  | TmFalse of info\\
  | TmIf of info * term * term * term\\
  | TmZero of info\\
  | TmSucc of info * term\\
  | TmPred of info * term\\
  | TmIsZero of info * term\\
(*Each abstract syntax tree node is annotated with a value of type info, \\
 *which describes what character position in which source file the node originated.*)\\
let rec isnumericalval t = match t with\\
    TmZero(\_) -> true\\
  | TmSucc(\_,t1) -> isnumericval t1 \\
  | \_ -> false\\
(*\_ matches anything, info needs to be matched; rec indicates it is recursive*)\\
let rec isval t = match t with\\
    TmTrue(\_) -> true\\
  | TmFalse(\_) -> true\\
  | t when isnumericval t -> true\\
  | \_ -> false\\
exception NoRuleApplies\\
let rec eval1 t = match t with\\
    TmIf(\_,TmTrue(\_),t2,t3) -> t2\\
  | TmIf(\_,TmFalse(\_),t2,t3) -> t3\\
  | TmIf(fi,t1,t2,t3) -> let t1' = eval1 t1 in TmIf(fi,t1',t2,t3)\\
  | TmSucc(fi,t1) -> let t1' = eval1 t1 in TmSucc(fi,t1')\\
  | TmPred(\_,TmZero(\_)) -> TmZero(dummyinfo)\\
  | TmPred(\_,TmSucc(\_,nv1)) when (isnumericval nv1) -> nv1\\
  | TmPred(fi,t1) -> let t1' = eval1 t1 in TmPred(fi,t1')\\
  | TmIsZero(\_,TmZero(\_)) -> TmTrue(dummyinfo)\\
  | TmIsZero(\_,TmSucc(\_,nv1)) when (isnumericval nv1) -> TmFalse(dummyinfo)\\
  | TmIsZero(fi,t1) -> let t1' = eval1 t1 in TmIsZero(fi,t1')\\
  | \_ -> raise NoRuleApplies\\
(*let ... in ... is a way to create local variables in the second expression*)\\
let rec eval t = \\
  try let t' = eval1 t in eval t'\\
  with NoRuleApplies -> t\\
}
\pagebreak
\section{The Untyped Lambda-Calculus}
\subsection{Basics}
\texttt{t ::=}\tab\tab terms:\\
\null\qquad \texttt{x}\tab\tab variable\\
\null\qquad \(\lambda\)\texttt{x.t}\tab\tab abstraction\\
\null\qquad \texttt{t t}\tab\tab application\\\\
The \textbf{concrete syntax} or surface syntax of the language refers to the strings of characers; the \textbf{abstract syntax} refers to an internal representation of programs as labeled trees (ASTs).
We avoid writing too many parentheses: application associates to the left and bodies of abstractions extend as far right as possible. 
\(\lambda\)\texttt{x.}\(\lambda\)\texttt{y.x y x} stands for the same tree as \(\lambda\)\texttt{x.(}\(\lambda\)\texttt{y.((x y) x))}.\\\\
Another subtlety is the use of metavariable for terms \texttt{t},\texttt{s},\texttt{u}, metavariable for variables \texttt{x},\texttt{y},\texttt{z} and object-language variables \texttt{x},\texttt{y},\texttt{z}.\\\\
An occurence of the variable \texttt{x} is said to be \textbf{bound} by abstraction \(\lambda\)\texttt{x.t} when it occurs in the body \texttt{t}. (\(\lambda\)\texttt{x} is a \textbf{binder} whose scope is \texttt{t}.)
An occurence of \texttt{x} is \textbf{free} if it is not bound by an enclosing abstraction. A term with no free variables is \textbf{closed}; closed terms are also called \textbf{combinators}. The simplest combinator is identity \texttt{id = }\(\lambda\)\texttt{x.x;}
\[\texttt{(}\lambda \texttt{x.t}_{12}\texttt{)t}_{2}\to\texttt{[x}\mapsto \texttt{t}_{2}\texttt{]t}_{12}\]
where \(\texttt{[x}\mapsto \texttt{t}_{2}\texttt{]t}_{12}\) means "the term obtained by replacing all free occurences of \texttt{x} in \(\texttt{t}_{12}\) by \(\texttt{t}_{2}\)". Following Church, a term of the form \(\texttt{(}\lambda \texttt{x.t}_{12}\texttt{)t}_{2}\to\texttt{[x}\)
is called a \textbf{redex} (reducible expression) and the operation of rewriting a redex according to the above rule is \textbf{beta-reduction}.
\begin{itemize}
\item \textbf{full beta-reduction}: any redex may be reduced ay any time; except this strategy in all of them the evaluation relation is a partial function: \texttt{t} evaluates in one step to at most one term \texttt{t}'.
\item \textbf{normal order}: the leftmost, outermost redex is always reduced first
\item \textbf{call by name}: same as normal order, but allow no reductions inside abstractions
\item \textbf{call by need}: used by Haskell; instead of re-evaluating an argument each time it is used, overwrites all occurences of the argument with its value the first time it is evaluated, avoiding subsequent re-evaluation.
    but this demands a reduction relation on abstract syntax graphs (why?) rather than syntax trees
\item \textbf{call by value}: used by most languages; only outermost redexes whose right-hand side has already been reduced to a value are reduced
    \[\texttt{id(id(}\lambda \texttt{z.id z))}\to \texttt{id(}\lambda \texttt{z.id z)}\to \lambda \texttt{z.id z}\]
    (lambda-abstractions are values) The call-by-value strategy is \textbf{strict} in the sense that the arguments to functions are always evaluated whether or not they are used by the body of the function. \textbf{Non-strict}, or lazy strategies such as call-by-name and call-by-need evaluate only the arguments that are actually used.
\end{itemize}
The choice of evaluation strategy actually makes little difference when discussing type systems.
\subsection{Programming in the Lambda-Calculus}
Multi-argument functions: use \textbf{higher-order functions} that yield functions as results: \(\texttt{f}=\lambda \texttt{x.}\lambda \texttt{y.s}; \texttt{f v w}\to^{*} \texttt{[y}\mapsto \texttt{w][x}\mapsto \texttt{v]s}\) This transformation is called \textbf{currying} in honor of Haskell Curry.\\\\
Church Booleans:\\
\(\texttt{tru}=\lambda \texttt{t.}\lambda \texttt{f.t;}\)\\
\(\texttt{fls}=\lambda \texttt{t.}\lambda \texttt{f.f;}\)\\
It basically chooses between first and second input.\\
\(\texttt{test}=\lambda \texttt{l.}\lambda \texttt{m.}\lambda \texttt{n.l m n;}\)\\
\(\texttt{test tru v w}\to \texttt{v}\) and \(\texttt{test fls v w}\to \texttt{w}\)\\
\(\texttt{and}=\lambda \texttt{b.}\lambda \texttt{c.b c fls;}\)\\
\null\qquad \(\texttt{and tru tru}\to \texttt{tru \underline{tru} fls}\to \texttt{tru}\)\\
\null\qquad \(\texttt{and tru fls}\to \texttt{tru \underline{fls} fls}\to \texttt{fls}\)\\
\null\qquad \(\texttt{and fls tru}\to \texttt{fls tru \underline{fls}}\to \texttt{fls}\)\\
\null\qquad \(\texttt{and fls fls}\to \texttt{fls fls \underline{fls}}\to \texttt{fls}\)\\
\begin{siderules}\color{blue}\textit{EXERCISE 5.2.1}\color{black}\\\\
\color{blue}Define \texttt{or} and \texttt{not} functions.\\\\\color{black}
\(\texttt{or}=\lambda \texttt{b.}\lambda \texttt{c.b tru c;}\)\\
\null\qquad \(\texttt{or tru tru}\to \texttt{tru \underline{tru} tru}\to \texttt{tru}\)\\
\null\qquad \(\texttt{or tru fls}\to \texttt{tru \underline{tru} fls}\to \texttt{tru}\)\\
\null\qquad \(\texttt{or fls tru}\to \texttt{fls tru \underline{tru}}\to \texttt{tru}\)\\
\null\qquad \(\texttt{or fls fls}\to \texttt{fls tru \underline{fls}}\to \texttt{fls}\)\\
\(\texttt{not}=\lambda \texttt{b.b fls tru;}\)
\end{siderules}
Using booleans, we can encode pairs of values as terms:\\
\(\texttt{pair}=\lambda \texttt{f.}\lambda \texttt{s.} \lambda \texttt{b.b f s;}\)\\
\(\texttt{fst}=\lambda \texttt{p.p tru;}\)\\
\(\texttt{snd}=\lambda \texttt{p.p fls;}\)\\
\(\texttt{fst(pair v w)}\to^{*}\texttt{v}\)\\\\
Define the Church numerals as:\\
\(\texttt{c}_{0}=\lambda \texttt{s.}\lambda \texttt{z.z;}\)\\
\(\texttt{c}_{1}=\lambda \texttt{s.}\lambda \texttt{z.s z;}\)\\
\(\texttt{c}_{2}=\lambda \texttt{s.}\lambda \texttt{z.s (s z);}\)\\
\(\texttt{c}_{3}=\lambda \texttt{s.}\lambda \texttt{z.s (s (s z));}\)\\
\texttt{etc.}\\
\(\texttt{scc}=\lambda \texttt{n.}\lambda \texttt{s.}\lambda \texttt{z.s (n s z);}\)\\
\(\texttt{scc c}_{n}\to \lambda \texttt{s.} \lambda \texttt{z.s (c}_{n} \texttt{ s z)}\to \lambda \texttt{s.} \lambda \texttt{z.s ((}\lambda \texttt{s}_{n}\texttt{.}\lambda \texttt{z}_{n}\texttt{.s}_{n}\texttt{ (...)) s z)}\)\\
\begin{siderules}\color{blue}\textit{EXERCISE 5.2.2}\color{black}\\\\
    \color{blue}Find another way to define the successor function.\color{black}\\\\
    \(\texttt{scc}=\lambda\texttt{n.}\lambda \texttt{s.}\lambda \texttt{z.n s (s z);}\)
\end{siderules}
\(\texttt{plus}=\lambda \texttt{m.}\lambda \texttt{n.}\lambda \texttt{s.}\lambda \texttt{z.m s (n s z);}\)\\
\(\texttt{times}=\lambda \texttt{m.}\lambda \texttt{n.m (plus n) c}_{0}\texttt{;}\)
\begin{siderules}\color{blue}\textit{EXERCISE 5.2.3}\color{black}\\\\
\color{blue}Is it possible to define multiplication on Church numerals without using \texttt{plus}?\\\\
\color{red}i dont know\color{black}
\end{siderules}
\begin{siderules}\color{blue}\textit{EXERCISE 5.2.4}\color{black}\\\\
        \color{blue}Define a term for raising one number to the power of another.\\\\\color{black}
        \(\texttt{power}=\lambda \texttt{m.}\lambda \texttt{n.n (times m) c}_{0}\texttt{;}\)
\end{siderules}
\(\texttt{iszro}=\lambda \texttt{n.m (}\lambda \texttt{x.fls) tru;}\)\\
\includegraphics{type6}\\
\(\texttt{zz}=\texttt{pair c}_{0} \texttt{ c}_{0}\texttt{;}\)\\
\(\texttt{ss}=\lambda \texttt{p.pair (snd p) (plus c}_{1}\texttt{ (snd p));}\)\\
\(\texttt{prd}=\lambda \texttt{m.fst (m ss zz);}\)
\begin{siderules}\color{blue}\textit{EXERCISE 5.2.5}\color{black}\\\\
    \color{blue}Use \texttt{prd} to define a subtraction function.\\\\\color{black}
    \(\texttt{sub}=\lambda \texttt{m.}\lambda \texttt{n.n prd m}\)
\end{siderules}
\begin{siderules}\color{blue}\textit{EXERCISE 5.2.6}\color{black}\\\\
    \color{blue} Approximately how many steps of evaluation are required to calculate \(\texttt{prd c}_{n}\)?\\\\\color{black}
    \includegraphics[width=8cm]{type7}\\
    \(21n+9\)
\end{siderules}
\begin{siderules}\color{blue}\textit{EXERCISE 5.2.7}\color{black}\\\\
    \color{blue} Write a function \texttt{equal} that tests two numbers for equality and returns a Church boolean.\\\\\color{black}
    \(\lambda \texttt{m.}\lambda \texttt{n.and (n prd m (}\lambda \texttt{a.fls) tru) (m prd n (}\lambda \texttt{a.fls) tru)} \)
\end{siderules}
\begin{siderules}\color{blue}\textit{EXERCISE 5.2.8}\color{black}\\\\
    \color{blue}A list can be represented in the lambda-calculus by its \texttt{fold} function. For example, the list \texttt{[x,y,z]} becomes a function that takes two arguments \texttt{c} and \texttt{n} 
    and returns \texttt{c x (c y (c z n)))}. What would the representation of \texttt{nil} be? \color{black} \texttt{n}.\\\\
    \color{blue}   Write a function \texttt{cons} that takes an element \texttt{h} and a list \texttt{t} and returns a list formed by prepending \texttt{h} to \texttt{t}. \color{black} 
    \(\texttt{cons}=\lambda \texttt{h.}\lambda \texttt{t.}\lambda \texttt{c.}\lambda \texttt{n.c h (t c n);}\)\\\\
    \color{blue}Write \texttt{isnil} and \texttt{head} functions, each taking a list parameter. \color{black}
\(\texttt{isnil}=\lambda \texttt{t.t (}\lambda \texttt{a.}\lambda \texttt{b.fls) tru;}\)\\
    \(\texttt{head}=\lambda \texttt{t.t tru fls}\)\\\\
    \color{blue}Finally, write a \texttt{tail} function for this representation of lists.\\\color{black}
    \(\texttt{tail}=\lambda \texttt{t.}\)
\end{siderules}
Enriching the calculus: we will use symbol \(\lambda\) for the pure lambda-calculus and \(\lambda \textbf{NB}\) for the enriched system with booleans and arithmetic expressions from section 2.\\\\
\(\texttt{realbool}=\lambda \texttt{b.b true false;}\)\\
\(\texttt{churchbool}=\lambda \texttt{b.if b then tru else fls;}\)\\
\(\texttt{realeq}=\lambda \texttt{m.}\lambda \texttt{n.(equal m n) true false;}\)\\
\(\texttt{realnat}=\lambda \texttt{m.m (}\lambda \texttt{x.succ x) 0;}\)\\\\
The reason primitive boolean and numbers come in handy is because of evaluation order. For example, \(\texttt{scc c}_{1}\) doesn't actually evaluate to \(\texttt{c}_{2}\):\\\\
\(\texttt{scc c}_{1} \to \lambda \texttt{s.}\lambda \texttt{z.s ((}\lambda \texttt{s'.}\lambda \texttt{z'.s' z') s z))}\)\\\\
By the rules of call-by-value evaluation we cannot reduce the redex. It is \textbf{behaviourally equivalent} to \(\texttt{c}_{2}\), but the leftover computation makes it difficult to check if our functions are behaving the way we expect it to.\\\\
\(\texttt{realnat (times c}_{2} \texttt{ c}_{2} \texttt{)}\to \texttt{4}\)\\\\
This conversion has the effect of supplying the two extra arguments that \(\texttt{times c}_{2} \texttt{ c}_{2}\) is waiting for, forcing all of the latent computation in its body.
\end{document}
